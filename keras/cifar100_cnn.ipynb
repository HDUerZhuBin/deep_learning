{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D\n",
    "\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 100\n",
    "epochs = 10\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(),\"saved_models\")\n",
    "model_name = \"keras_cifar100_trained_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data,train_labels),(test_data,test_labels) = cifar100.load_data()\n",
    "\n",
    "train_data = train_data.astype(\"float32\")\n",
    "test_data = test_data.astype(\"float32\")\n",
    "train_data /= 255\n",
    "test_data /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape:(50000, 32, 32, 3)\n",
      "test_data.shape:(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_data.shape:{}\".format(train_data.shape))\n",
    "print(\"test_data.shape:{}\".format(test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.keras.utils.to_categorical(y=train_labels,num_classes=num_classes)\n",
    "test_labels = tf.keras.utils.to_categorical(y=test_labels,num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (32,32,3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3),\n",
    "                padding=\"same\",input_shape=input_shape))\n",
    "model.add(Activation(activation=\"relu\"));\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3)))\n",
    "model.add(Activation(activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),\n",
    "                padding=\"same\"))\n",
    "model.add(Activation(activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3)))\n",
    "model.add(Activation(activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512))\n",
    "model.add(Activation(activation=\"relu\"))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(units=num_classes))\n",
    "model.add(Activation(activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "decay = 1e-6\n",
    "\n",
    "loss = tf.keras.losses.categorical_crossentropy\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr,decay=decay)\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "model.compile(loss=loss,\n",
    "             optimizer=optimizer,\n",
    "             metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 1,297,028\n",
      "Trainable params: 1,297,028\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using real-time data augmentation\n",
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 4.3406 - accuracy: 0.0395 - val_loss: 4.0012 - val_accuracy: 0.0999\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 3.9162 - accuracy: 0.0992 - val_loss: 3.6268 - val_accuracy: 0.1527\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 3.6803 - accuracy: 0.1351 - val_loss: 3.4139 - val_accuracy: 0.1950\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 3.5326 - accuracy: 0.1584 - val_loss: 3.2835 - val_accuracy: 0.2130\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 3.4090 - accuracy: 0.1844 - val_loss: 3.2130 - val_accuracy: 0.2302\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 3.3161 - accuracy: 0.2007 - val_loss: 3.0562 - val_accuracy: 0.2568\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 3.2222 - accuracy: 0.2176 - val_loss: 3.0019 - val_accuracy: 0.2653\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 3.1588 - accuracy: 0.2316 - val_loss: 2.8923 - val_accuracy: 0.2886\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 3.0908 - accuracy: 0.2426 - val_loss: 2.9461 - val_accuracy: 0.2792\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 3.0420 - accuracy: 0.2525 - val_loss: 2.7771 - val_accuracy: 0.3102\n",
      "saved trained model at /home/zhubin/deep_learning/keras/saved_models/keras_cifar100_trained_model.h5 \n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 2.7769 - accuracy: 0.3102\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2296bde39451>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test loss:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test acc:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'score' is not defined"
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    print(\"not using data augmentation\")\n",
    "    model.fit(train_data,train_labels,\n",
    "             batch_size=batch_size,\n",
    "             epochs=epochs,\n",
    "             verbose=1,\n",
    "             validation_data=(test_data,test_labels),\n",
    "             shuffle=True)\n",
    "    \n",
    "\n",
    "else:\n",
    "    print(\"using real-time data augmentation\")\n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=False,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.,\n",
    "    zoom_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode=\"nearest\",\n",
    "    cval=0,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0.0)\n",
    "    \n",
    "    datagen.fit(train_data)\n",
    "    \n",
    "    model.fit_generator(datagen.flow(train_data,train_labels,batch_size=batch_size),\n",
    "                       epochs=epochs,\n",
    "                       verbose=1,\n",
    "                       validation_data=(test_data,test_labels))\n",
    "    \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir,model_name)\n",
    "model.save(model_path)\n",
    "print(\"saved trained model at %s \" % model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 59us/sample - loss: 2.7769 - accuracy: 0.3102\n",
      "test loss:2.7768975830078126\n",
      "test acc:0.3102000057697296\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_data,test_labels,verbose=1)\n",
    "print(\"test loss:{}\".format(scores[0]))\n",
    "print(\"test acc:{}\".format(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
