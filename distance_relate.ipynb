{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "对向量之间的距离进行度量:\n",
    "1.使用一阶范数进行度量;\n",
    "2.使用欧式距离进行度量;\n",
    "3.使用Mahalanobis距离进行度量;\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 向量一阶范数距离度量\n",
    "# 将两个向量各个维度进行作差取绝对值,并且累加作为两个向量之间的距离\n",
    "# data:data1,data2,且数据类型为np.adarray\n",
    "# 数据的shape为(n_samples,n_features):行向量为每一个向量数据样本,列向量为所有数据样本的某个特征字段\n",
    "# normalized为是否对数据样本中的每一个特征字段进行Z-SCORE标准化\n",
    "def abs_vec_dist(data1,data2,normalized=False):\n",
    "    dist_list = list()\n",
    "    \n",
    "    if normalized:\n",
    "        data1 = scale(data1)\n",
    "        data2 = scale(data2)\n",
    "        \n",
    "    for (vec1,vec2) in zip(data1,data2):\n",
    "#         print(\"vec1:{},vec2:{}\".format(vec1,vec2))\n",
    "        temp_ret = abs(vec1-vec2)\n",
    "#         print(\"temp_ret:{}\".format(temp_ret))\n",
    "        sum_abs_dimension_diff = sum(temp_ret)\n",
    "#         print(\"temp_dist:{}\".format(sum_abs_dimension_diff))\n",
    "#         print(\"*********\")\n",
    "        dist_list.append(sum_abs_dimension_diff)\n",
    "        \n",
    "    return dist_list\n",
    "    \n",
    "    \n",
    "# 向量二阶范数,欧几里的距离\n",
    "# 将两个向量各个维度进行作差取平方,累加之后并开方作为两个向量之间的距离\n",
    "# data:data1,data2,且数据类型为np.adarray\n",
    "# 数据的shape为(n_samples,n_features):行向量为每一个向量数据样本,列向量为所有数据样本的某个特征字段\n",
    "# normalized为是否对数据样本中的每一个特征字段进行Z-SCORE标准化\n",
    "def eculidean_vec_dist(data1,data2,normalized=False):\n",
    "    dist_list = list() \n",
    "    if normalized:\n",
    "        data1 = scale(data1)\n",
    "        data2 = scale(data2)\n",
    "           \n",
    "    for (vec1,vec2) in zip(data1,data2):\n",
    "        dist_list.append(np.sqrt(np.sum(np.power((vec1-vec2),2))))\n",
    "        \n",
    "    return dist_list\n",
    "\n",
    "# # mahalanobis距离\n",
    "# # 将需要比较的向量转换为各个维度是线性无关(使用PCA方法),并且各个维度进行了标准化后(使用sklearn.preprocessing中的scale方法)\n",
    "# # 转换为新的向量之后使用欧式距离进行度量\n",
    "# # data:data1,data2,且数据类型为np.adarray\n",
    "# # 数据的shape为(n_samples,n_features):行向量为每一个向量数据样本,列向量为所有数据样本的某个特征字段\n",
    "# # normalized为是否对数据样本中的每一个特征字段进行Z-SCORE标准化\n",
    "# def mahalanobis_vec_dist(data1,data2,normalized=False):\n",
    "#     dist_list = list()\n",
    "#     if normalized:\n",
    "#         data1 = scale(data1)\n",
    "#         data2 = scale(data2)\n",
    "        \n",
    "#     pca_model = PCA()\n",
    "#     #PCA使用训练数据data1进行     \n",
    "#     pca_model.fit(X=data1)\n",
    "#     #transform方法将数据转换为各个维度线性无关的数据\n",
    "#     pca_data1 = pca_model.transform(data1)\n",
    "#     pca_data2 = pca_model.transform(data2)\n",
    "#     print(\"pca_data1.shape:{},pca_data2.shape:{}\".format(pca_data1.shape,pca_data2.shape))\n",
    "#     print(\"pca_data1\\n:{}\\npca_data2\\n:{}\".format(pca_data1,pca_data2))\n",
    "    \n",
    "    \n",
    "#     #通过Z-SCORE标准化方法将线性无关数据进一步标准化,用以计算mahalanobis     \n",
    "#     new_data1 = scale(pca_data1)\n",
    "#     new_data2 = scale(pca_data2)\n",
    "#     print(\"new_data1.shape:{},new_data2.shape:{}\".format(new_data1.shape,new_data2.shape))\n",
    "#     print(\"new_data1\\n:{}\\nnew_data2\\n:{}\".format(new_data1,new_data2))\n",
    "    \n",
    "    \n",
    "#     #对于转化后数据的欧几里的距离就是mahalanobis距离\n",
    "#     #ref:https://zhuanlan.zhihu.com/p/46626607\n",
    "#     dist_list = eculidean_vec_dist(new_data1,new_data2)\n",
    "    \n",
    "#     return dist_list\n",
    "\n",
    "# the data1 is training data\n",
    "def mahalanobis_vec_dist(data1,data2,normalized=False):\n",
    "    dist_list = list()\n",
    "    if normalized:\n",
    "        data1 = scale(data1)\n",
    "        data2 = scale(data2)\n",
    "    \n",
    "    #求训练数据的协方差矩阵     \n",
    "    train_cov_matrix = np.cov(data1.T)\n",
    "    #求训练数据协方差矩阵的逆据阵\n",
    "    inv_train_cov_matrix = np.linalg.inv(train_cov_matrix)\n",
    "    \n",
    "    for (vec1,vec2) in zip(data1,data2):\n",
    "        diff_vec = vec1 - vec2\n",
    "        temp_ret = np.dot(diff_vec.T,inv_train_cov_matrix,diff_vec)\n",
    "        ret = np.dot()\n",
    "        dist_list.append(np.sqrt(temp_ret))\n",
    "        \n",
    "    return dist_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([[2,5,7],[4,7,8]])\n",
    "v2 = np.array([[2,4,9],[5,6,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_ret = scale(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_abs_list = abs_vec_dist(v1,v2)\n",
    "ret_ecu_list = eculidean_vec_dist(v1,v2)\n",
    "# ret_mahala_list = mahalanobis_vec_dist(v1,v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3]\n",
      "[2.23606797749979, 1.7320508075688772]\n"
     ]
    }
   ],
   "source": [
    "print(ret_abs_list)\n",
    "print(ret_ecu_list)\n",
    "# print(ret_mahala_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.使用PCA将原始数据进行特征变换,变换为各个特征之间是线性无关\n",
    "##### 2.将变换之后的数据进行各个特征维度标准化(Z-SCORE)\n",
    "##### 3.对数据之间的距离使用欧式距离进行度量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_matrix = np.random.random((20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_ret = np.cov(test_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_ret.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_cov_ret = np.linalg.inv(cov_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_cov_ret.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07184009, -0.00015561,  0.02020436,  0.00861818, -0.02785314],\n",
       "       [-0.00015561,  0.06933355, -0.02095867,  0.01431836,  0.01364422],\n",
       "       [ 0.02020436, -0.02095867,  0.06664079, -0.00257308,  0.00351958],\n",
       "       [ 0.00861818,  0.01431836, -0.00257308,  0.09476555,  0.01717466],\n",
       "       [-0.02785314,  0.01364422,  0.00351958,  0.01717466,  0.06420095]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21.157503  , -4.00447015, -8.41929014, -3.62483681, 11.46133421],\n",
       "       [-4.00447015, 17.90009973,  7.09746144, -1.12752955, -5.62896923],\n",
       "       [-8.41929014,  7.09746144, 20.19799579,  1.44793625, -6.65565317],\n",
       "       [-3.62483681, -1.12752955,  1.44793625, 11.92584518, -4.60269404],\n",
       "       [11.46133421, -5.62896923, -6.65565317, -4.60269404, 23.3409615 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_cov_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.array([1,5,7,8,6])\n",
    "arr2 = np.array([5,8,7,4,2])\n",
    "vec_diff = arr1 - arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4, -3,  0,  4,  4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.dot(vec_diff.T,inv_cov_ret)\n",
    "b = np.dot(a,vec_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731.8844135964315"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "l = [1,5,7,8,9]\n",
    "arr_l = np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
